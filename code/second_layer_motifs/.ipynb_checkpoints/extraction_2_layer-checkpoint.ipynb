{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data\n",
    "import matplotlib\n",
    "import os\n",
    "import sys\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import aitac_v2\n",
    "import plot_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 141\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-trained model to use\n",
    "model_name = 'mini_sample'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../outputs/mini_sample/layer2_motifs/ exists\n"
     ]
    }
   ],
   "source": [
    "#create output figure directory\n",
    "output_file_path = \"../../outputs/\" + model_name + \"/layer2_motifs/\"\n",
    "directory = os.path.dirname(output_file_path)\n",
    "if not os.path.exists(directory):\n",
    "    print(\"Creating directory %s\" % output_file_path)\n",
    "    os.makedirs(directory)\n",
    "else:\n",
    "     print(\"Directory %s exists\" % output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "x = np.load('../../BRCA_data/mini_sample_one_hot_seqs.npy')\n",
    "x = x.astype(np.float32)\n",
    "y = np.load('../../BRCA_data/mini_sample_cell_type_array.npy')\n",
    "y = y.astype(np.float32)\n",
    "peak_names = np.load('../../BRCA_data/mini_sample_peak_names.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load names of test set from original model\n",
    "test_peaks = np.load(\"../../outputs/\" + model_name + \"/training/test_OCR_names.npy\")\n",
    "idx = np.in1d(peak_names, test_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "eval_data, eval_labels, eval_names = x[idx, :, :], y[idx, :], peak_names[idx]\n",
    "train_data, train_labels, train_names = x[~idx, :, :], y[~idx, :], peak_names[~idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "eval_dataset = torch.utils.data.TensorDataset(torch.from_numpy(eval_data), torch.from_numpy(eval_labels))\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained model weights\n",
    "checkpoint = torch.load(\"../../models/\" + model_name + \".ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model \n",
    "model = aitac_v2.ConvNet(num_classes).to(device)\n",
    "checkpoint2 = model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy original model weights into new model\n",
    "for i, (layer_name, layer_weights) in enumerate(checkpoint.items()):\n",
    "        new_name = list(checkpoint2.keys())[i]\n",
    "        checkpoint2[new_name] = layer_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights into new model\n",
    "model.load_state_dict(checkpoint2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 200, 166])\n",
      "weighted_cor is 0.5052579089850296\n",
      "number of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "#get layer 2 motifs\n",
    "predictions, max_act_layer2, activations_layer2, act_index_layer2 = aitac_v2.test_model(eval_loader, model, device)\n",
    "\n",
    "correlations = plot_utils.plot_cors(eval_labels, predictions, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get PWMs of second layer motifs\n",
    "plot_utils.get_memes2(activations_layer2, eval_data, eval_labels, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files\n",
    "np.save(output_file_path + \"second_layer_maximum_activations.npy\", max_act_layer2)\n",
    "np.save(output_file_path + \"second_layer_maxact_index.npy\", act_index_layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 300)\n",
      "[[0.7326865  0.7258493  0.40777296 ... 0.63635755 0.728843   0.9178561 ]\n",
      " [0.8193272  0.922959   0.585779   ... 0.78894603 0.92611015 0.7782495 ]\n",
      " [0.7876787  0.8905411  0.73525065 ... 0.78446746 0.89635366 0.9944668 ]\n",
      " ...\n",
      " [0.8324806  0.7036093  0.5567735  ... 0.78909206 0.7539064  0.77290446]\n",
      " [0.8127548  0.7196656  0.58814245 ... 0.85957146 0.876065   0.90636307]\n",
      " [0.7485167  0.798457   0.49164894 ... 0.78751886 0.8667381  0.88092035]]\n"
     ]
    }
   ],
   "source": [
    "sec_ly_mx_acty = np.load('../../outputs/first_approach/layer2_motifs/second_layer_maximum_activations.npy')\n",
    "print(sec_ly_mx_acty.shape)\n",
    "print(sec_ly_mx_acty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 300)\n",
      "[[ 19. 193. 232. ...   1.  73.  23.]\n",
      " [146.  41. 198. ...  95. 170. 108.]\n",
      " [167.  52. 131. ...  76. 223. 223.]\n",
      " ...\n",
      " [106. 156. 188. ...   3. 141. 189.]\n",
      " [204. 236.  24. ... 152.  13. 228.]\n",
      " [224. 114. 203. ...  94.  16.  75.]]\n"
     ]
    }
   ],
   "source": [
    "sec_ly_mx_acty_idx = np.load('../../outputs/first_approach/layer2_motifs/second_layer_maxact_index.npy')\n",
    "print(sec_ly_mx_acty_idx.shape)\n",
    "print(sec_ly_mx_acty_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
