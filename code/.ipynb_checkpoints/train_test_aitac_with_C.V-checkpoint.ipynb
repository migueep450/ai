{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With 10 - fold - cross - validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.utils.data\n",
    "import matplotlib\n",
    "import os\n",
    "import sys\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import aitac\n",
    "import plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../outputs/valid10x10/ exists\n"
     ]
    }
   ],
   "source": [
    "#create output directory\n",
    "output_file_path = \"../outputs/valid10x10/\"\n",
    "directory = os.path.dirname(output_file_path)\n",
    "if not os.path.exists(directory):\n",
    "    print(\"Creating directory %s\" % output_file_path)\n",
    "    os.makedirs(directory)\n",
    "else:\n",
    "     print(\"Directory %s exists\" % output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 141\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "num_filters = 300\n",
    "run_num = 'first'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "x = np.load('../BRCA_data/mini_sample_one_hot_seqs.npy')\n",
    "x = x.astype(np.float32)\n",
    "y = np.load('../BRCA_data/mini_sample_cell_type_array.npy')\n",
    "y = y.astype(np.float32)\n",
    "peak_names = np.load('../BRCA_data/mini_sample_peak_names.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x, y, peak_names, output_file_path):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state = 123)\n",
    "\n",
    "    pred_all = []\n",
    "    corr_all = []\n",
    "    peak_order = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        train_data, eval_data = x[train_index, :, :], x[test_index, :, :]\n",
    "        train_labels, eval_labels = y[train_index, :], y[test_index, :]\n",
    "        train_names, eval_name = peak_names[train_index], peak_names[test_index]\n",
    "\n",
    "        # Data loader\n",
    "        train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data), torch.from_numpy(train_labels))\n",
    "        print(train_dataset)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        print(train_loader)\n",
    "        \n",
    "        eval_dataset = torch.utils.data.TensorDataset(torch.from_numpy(eval_data), torch.from_numpy(eval_labels))\n",
    "        eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "        # create model \n",
    "        model = aitac.ConvNet(num_classes, num_filters).to(device)\n",
    "\n",
    "        # Loss and optimizer\n",
    "        criterion = aitac.pearson_loss\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # train model\n",
    "        '''\n",
    "        model, best_loss = aitac.train_model(train_loader, eval_loader, model, device, criterion,  optimizer, num_epochs, output_file_path)\n",
    "\n",
    "        # Predict on test set\n",
    "        predictions, max_activations, max_act_index = aitac.test_model(eval_loader, model, device)\n",
    "        \n",
    "        # plot the correlations histogram\n",
    "        correlations = plot_utils.plot_cors(eval_labels, predictions, output_file_path)\n",
    "\n",
    "        pred_all.append(predictions)\n",
    "        corr_all.append(correlations)\n",
    "        peak_order.append(eval_name)\n",
    "    \n",
    "    pred_all = np.vstack(pred_all)\n",
    "    corr_all = np.hstack(corr_all)\n",
    "    peak_order = np.hstack(peak_order)\n",
    "\n",
    "    return pred_all, corr_all, peak_order\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x7f5794507280>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5710998c70>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f5710998b80>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5711047100>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f5794494520>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5710998d00>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f5794494400>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f57944f7400>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f57944f7040>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f57109987f0>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f5710998c40>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5710998c70>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f57944fce80>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5711047340>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f57944fcdc0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5710998e80>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f5794507070>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5710998ac0>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7f5794507280>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f57944940d0>\n"
     ]
    }
   ],
   "source": [
    "cross_validate(x, y, peak_names, output_file_path) # 12' | 17.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4cf57f97ebcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 12' | 17.34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "predictions, correlations, peak_order = cross_validate(x, y, peak_names, output_file_path) # 12' | 17.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.utils.data.get_worker_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(output_file_path + \"predictions_trial\" + run_num + \".npy\", predictions)\n",
    "np.save(output_file_path + \"correlations_trial\" + run_num + \".npy\", correlations)\n",
    "np.save(output_file_path + \"peak_order\" + run_num + \".npy\", peak_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tr = np.load(output_file_path + \"predictions_trial\" + run_num + \".npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 141)\n",
      "[[-2.1759357  -2.2475684   1.3170478  ...  0.92555666  0.48664138\n",
      "   0.4101336 ]\n",
      " [-3.8181725  -4.0997725   1.5997989  ...  1.3199861   1.0771232\n",
      "   1.0127945 ]\n",
      " [-3.7817397  -3.943818    1.4862937  ...  1.2669295   1.1656965\n",
      "   1.1460701 ]\n",
      " ...\n",
      " [-0.5498084  -0.66493     0.09440688 ...  0.28931335  0.2036487\n",
      "   0.19308531]\n",
      " [-0.16605252 -0.2045662   0.10259235 ...  0.16371793 -0.03135055\n",
      "  -0.03287304]\n",
      " [-0.14722002 -0.13741028  0.21233973 ...  0.02480217 -0.13214831\n",
      "  -0.10751709]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_tr.shape)\n",
    "print(pre_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = np.load(output_file_path + \"correlations_trial\" + run_num + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[ 0.11152916  0.20347479  0.7627214   0.64401011  0.74574792  0.67680965\n",
      "  0.52909116  0.52269603  0.434583    0.6932973   0.14449857 -0.02118328\n",
      "  0.1050344   0.47564544  0.59199979  0.64276615  0.39676618  0.59357292\n",
      "  0.57092798  0.30739773 -0.27065144  0.60161778  0.64359082  0.51851467\n",
      "  0.63183773  0.70501281  0.44582928  0.6512335   0.64564099  0.40760471\n",
      "  0.55978016  0.5353844   0.73902046  0.67735676  0.74258931  0.63297987\n",
      "  0.65288257  0.46116633  0.53141075  0.4925484   0.61032634  0.34804016\n",
      "  0.27505474  0.54817038  0.48851004  0.44129074  0.44406787  0.68675175\n",
      "  0.67973497  0.36224065  0.05119919  0.75699778  0.5358313   0.55007052\n",
      "  0.55506001  0.75840302  0.73609826  0.46285019  0.56945155  0.71048137\n",
      "  0.54536291  0.45592709  0.597265    0.7419421   0.68726956  0.656477\n",
      "  0.30166545  0.51630278  0.61866179  0.48581838 -0.119609    0.62682722\n",
      "  0.38330817  0.55082049  0.55513511  0.6083669   0.5360829   0.67323939\n",
      "  0.59680607  0.22580315 -0.01939756  0.66123902  0.67687684  0.76453538\n",
      "  0.55747497  0.61671718  0.64116752  0.566842    0.50736744  0.67150239\n",
      " -0.07910677  0.62902188  0.43813393  0.420346    0.60981142  0.68319871\n",
      "  0.63552231  0.60970569  0.69501953  0.34014259]\n"
     ]
    }
   ],
   "source": [
    "print(cor.shape)\n",
    "print(cor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
