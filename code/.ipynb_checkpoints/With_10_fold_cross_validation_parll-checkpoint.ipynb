{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function get_worker_info at 0x7fed6f076160>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.utils.data\n",
    "import matplotlib\n",
    "import os\n",
    "import sys\n",
    "matplotlib.use('Agg')\n",
    "import multiprocessing as mp\n",
    "\n",
    "import aitac\n",
    "import plot_utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../outputs/valid10x10/ exists\n"
     ]
    }
   ],
   "source": [
    "#create output directory\n",
    "output_file_path = \"../outputs/valid10x10/\"\n",
    "directory = os.path.dirname(output_file_path)\n",
    "if not os.path.exists(directory):\n",
    "    print(\"Creating directory %s\" % output_file_path)\n",
    "    os.makedirs(directory)\n",
    "else:\n",
    "     print(\"Directory %s exists\" % output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 141\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "num_filters = 300\n",
    "run_num = 'second'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "x = np.load('../BRCA_data/mini_sample_one_hot_seqs.npy')\n",
    "x = x.astype(np.float32)\n",
    "y = np.load('../BRCA_data/mini_sample_cell_type_array.npy')\n",
    "y = y.astype(np.float32)\n",
    "peak_names = np.load('../BRCA_data/mini_sample_peak_names.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = KFold(n_splits=10, shuffle=True, random_state = 123) #creamos los cachos que van a ir separados\n",
    "folds = list(splitter.split(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_models(x, y, peak_names, output_file_path, split):\n",
    "    \"\"\"\n",
    "    Helper function to benchmark models --> it executes the training and the testing of the model with a part of our data\n",
    "    X : array\n",
    "    y : array\n",
    "    split : tuple\n",
    "    Training and test indices (split[train], split[test])\n",
    "    \"\"\"\n",
    "    \n",
    "    torch.set_num_threads(1)\n",
    "    \n",
    "    #split the data\n",
    "    train = 0\n",
    "    test = 1\n",
    "    \n",
    "    train_data, eval_data = x[split[train], :, :], x[split[test], :, :]\n",
    "    train_labels, eval_labels = y[split[train], :], y[split[test], :]\n",
    "    train_names, eval_name = peak_names[split[train]], peak_names[split[test]]\n",
    "    \n",
    "    #Data loader\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data), torch.from_numpy(train_labels))\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    eval_dataset = torch.utils.data.TensorDataset(torch.from_numpy(eval_data), torch.from_numpy(eval_labels))\n",
    "    eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create model \n",
    "    model = aitac.ConvNet(num_classes, num_filters).to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = aitac.pearson_loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # train model\n",
    "    model, best_loss = aitac.train_model(train_loader, eval_loader, model, device, criterion,  optimizer, num_epochs, output_file_path)\n",
    "\n",
    "    # Predict on test set\n",
    "    predictions, max_activations, max_act_index = aitac.test_model(eval_loader, model, device)\n",
    "\n",
    "    # plot the correlations histogram\n",
    "    correlations = plot_utils.plot_cors(eval_labels, predictions, output_file_path)\n",
    "    \n",
    "    results = [predictions, correlations, eval_name]\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the parallization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the best model weights at Epoch [1], Best Valid Loss: 0.6827\n",
      "Saving the best model weights at Epoch [2], Best Valid Loss: 0.6592\n",
      "Saving the best model weights at Epoch [3], Best Valid Loss: 0.6461\n",
      "Saving the best model weights at Epoch [4], Best Valid Loss: 0.6382\n",
      "Saving the best model weights at Epoch [5], Best Valid Loss: 0.6357\n",
      "weighted_cor is 0.3453173649766286\n",
      "number of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pool = mp.Pool(3)\n",
    "# Python can count the available cores for you in most cases: mp.cpu_count()\n",
    "pool = mp.Pool(processes=1) # 2cpus:9' | 3cpus:9' | 10processs:9' processeses = 10 | 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_all = []\n",
    "correlations_all = []\n",
    "peak_order_all = []\n",
    "def log_result(results):\n",
    "    '''\n",
    "    Take the results from the different cross validation process and put them together for the next step\n",
    "    '''\n",
    "    predictions_all.append(results[0])\n",
    "    correlations_all.append(results[1])\n",
    "    peak_order_all.append(results[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos = pool.map(benchmark_models, folds) # 8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for fold in range(1): # We do the k-fold cross validation process\n",
    "    pool.apply_async(benchmark_models, args=(x, y, peak_names, output_file_path,folds[fold]), callback = log_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 138.28150033950806 seconds ---\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % ((end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 141)\n",
      "[[-4.1411767  -4.4942946   2.8506343  ...  1.9243295   0.7322075\n",
      "   0.63073987]\n",
      " [-2.6575267  -2.8265278   1.477456   ...  1.060821    0.6428787\n",
      "   0.6315372 ]\n",
      " [-2.5525937  -2.8361564   1.0452759  ...  1.1196467   0.55728346\n",
      "   0.43491462]\n",
      " ...\n",
      " [-3.939746   -4.416634    2.4228427  ...  1.6891941   1.0567546\n",
      "   0.7317235 ]\n",
      " [-3.5343888  -4.1001406   1.394879   ...  1.1335149   0.9797529\n",
      "   0.7878465 ]\n",
      " [-2.9661171  -3.5968142   1.5589011  ...  1.1235495   0.8489444\n",
      "   0.6138202 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions_all = np.vstack(predictions_all)\n",
    "print(predictions_all.shape)\n",
    "print(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[-0.03796543 -0.07729042  0.6312153   0.52034206  0.67949516  0.48805899\n",
      "  0.62585262  0.28420466  0.58397668  0.51585311 -0.03796543 -0.07729042\n",
      "  0.6312153   0.52034206  0.67949516  0.48805899  0.62585262  0.28420466\n",
      "  0.58397668  0.51585311 -0.03796543 -0.07729042  0.6312153   0.52034206\n",
      "  0.67949516  0.48805899  0.62585262  0.28420466  0.58397668  0.51585311\n",
      " -0.0396199  -0.07178639  0.63946932  0.52415306  0.68731179  0.48257162\n",
      "  0.61297366  0.2606187   0.57776137  0.512845   -0.0396199  -0.07178639\n",
      "  0.63946932  0.52415306  0.68731179  0.48257162  0.61297366  0.2606187\n",
      "  0.57776137  0.512845   -0.0396199  -0.07178639  0.63946932  0.52415306\n",
      "  0.68731179  0.48257162  0.61297366  0.2606187   0.57776137  0.512845\n",
      " -0.05519678 -0.07679066  0.62896369  0.52993627  0.69207883  0.48150297\n",
      "  0.61888756  0.27522814  0.58279148  0.5138411  -0.05519678 -0.07679066\n",
      "  0.62896369  0.52993627  0.69207883  0.48150297  0.61888756  0.27522814\n",
      "  0.58279148  0.5138411  -0.05519678 -0.07679066  0.62896369  0.52993627\n",
      "  0.69207883  0.48150297  0.61888756  0.27522814  0.58279148  0.5138411\n",
      " -0.05230375 -0.09343484  0.63996576  0.52847365  0.69601017  0.49210666\n",
      "  0.60732669  0.26177978  0.57438929  0.49927164]\n"
     ]
    }
   ],
   "source": [
    "correlations_all = np.hstack(correlations_all)\n",
    "print(correlations_all.shape)\n",
    "print(correlations_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "peak_order_all =  np.hstack(peak_order_all)\n",
    "print(peak_order_all.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
